# ğŸ§  Chatbot Project (FAISS + Gemini)

This project is a simple command-line chatbot that answers questions using an AI model (Google Gemini) and a set of documents stored in a **FAISS** vector index.  
All `.txt` files placed in the `knowledge_base/` folder are automatically processed and used as the chatbotâ€™s knowledge base.

---

## Project Scope

This project implements a local Retrieval-Augmented Generation (RAG) chatbot that:
âœ”ï¸ Uses a FAISS vector index for retrieval
âœ”ï¸ Supports plain `.txt` knowledge bases
âœ”ï¸ Runs as a command-line interface

This project does _not_ include:
âŒ Web UI
âŒ User authentication
âŒ Advanced safety filters beyond prompt constraints

---

## Guardrails & Responsible Use

To reduce risk of unsafe or hallucinated outputs:

- We use strict system prompts to limit the LLM to context from indexed documents only.
- User queries are checked for emptiness before processing.
- Files loaded into FAISS are filtered to `.txt` formats only.

âš ï¸ Limitations

- The system does not verify correctness of responses beyond retrieved context.
- It should not be used for critical advice (e.g., medical, legal).

---

## ğŸ“Œ Features

- Loads multiple `.txt` files as knowledge sources
- Embeds all documents using **Gemini Embeddings**
- Stores vectors in a **FAISS index**
- Uses **Retrieval-Augmented Generation (RAG)**
- Simple **CLI interface** for interactive chatting
- Custom system prompt to control chatbot behavior

---

## Sample Interaction

- Ask a question about the documents: What is X?
- Answer: X is defined asâ€¦

---

## ğŸ“¦ Requirements

- Python **3.8+**
- A Google **Gemini API Key**

âš™ï¸ Setup & Run

Follow these steps to run the chatbot:

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Create a .env file in the project root and add your Gemini API key

GOOGLE_API_KEY= YOUR_API_KEY

### 3. Run the chatbot

```bash
python main.py
```
