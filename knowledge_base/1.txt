LangChain is the easiest way to start building agents and applications powered by LLMs. With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more. LangChain provides a pre-built agent architecture and model integrations to help you get started quickly and seamlessly incorporate LLMs into your agents and applications.
We recommend you use LangChain if you want to quickly build agents and autonomous applications. Use LangGraph, our low-level agent orchestration framework and runtime, when you have more advanced needs that require a combination of deterministic and agentic workflows, heavy customization, and carefully controlled latency.
LangChain agents are built on top of LangGraph in order to provide durable execution, streaming, human-in-the-loop, persistence, and more. You do not need to know LangGraph for basic LangChain agent usage.
​
Philosophy

LangChain exists to be the easiest place to start building with LLMs, while also being flexible and production-ready.

LangChain is driven by a few core beliefs:
Large Language Models (LLMs) are great, powerful new technology.
LLMs are even better when you combine them with external sources of data.
LLMs will transform what the applications of the future look like. Specifically, the applications of the future will look more and more agentic.
It is still very early on in that transformation.
While it’s easy to build a prototype of those agentic applications, it’s still really hard to build agents that are reliable enough to put into production.
With LangChain, we have two core focuses:
1-We want to enable developers to build with the best models.
Different providers expose different APIs, with different model parameters and different message formats. Standardizing these model inputs and outputs is a core focus, making it easy for developer to easily change to the most recent state-of-the-art model, avoiding lock-in.
2-We want to make it easy to use models to orchestrate more complex flows that interact with other data and computation.
Models should be used for more than just text generation - they should also be used to orchestrate more complex flows that interact with other data. LangChain makes it easy to define tools that LLMs can use dynamically, as well as help with parsing of and access to unstructured data.
​
